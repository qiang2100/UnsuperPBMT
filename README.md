
## Dependencies

* Python 3
* [NumPy](http://www.numpy.org/)
* [Scipy](https://www.scipy.org/)
* [Nltk](http://www.nltk.org/)
* [textstat](https://pypi.org/project/textstat/)
* [gensim](https://pypi.org/project/gensim/)
* [Moses](http://www.statmt.org/moses/) (clean and tokenize text / train PBSMT model)
* [fastBPE](https://github.com/glample/fastBPE) (generate and apply BPE codes)
* [MUSE](https://github.com/facebookresearch/MUSE) (generate cross-lingual embeddings)


# Prior Work

1. Download corpus from English Wikipeida dump [Here] (https://dumps.wikimedia.org/enwiki/)
2. run 'sp


